{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2525fb2f",
   "metadata": {},
   "source": [
    "<div style=\"align: center; margin: 0; padding: 0; height: 250px;\">\n",
    "    <br>\n",
    "    <img src=\"https://storage.googleapis.com/kaggle-datasets-images/1479517/2444963/1aaa3760e7dd34a87af175482c1514ae/dataset-cover.jpg\" style=\"display:block; margin:auto; width:65%; height:100%;\">\n",
    "</div><br><br>\n",
    "\n",
    "<div style=\"letter-spacing:normal; opacity:1.;\">\n",
    "<!--   https://xkcd.com/color/rgb/   -->\n",
    "  <p style=\"text-align:center; background-color: lightsalmon; color: Jaguar; border-radius:10px; font-family:monospace; \n",
    "            line-height:1.4; font-size:32px; font-weight:bold; text-transform: uppercase; padding: 9px;\">\n",
    "            <strong>Bank Credit Scoring Dataset</strong></p>  \n",
    "            \n",
    "  <p style=\"text-align:center; background-color:romance; color: Jaguar; border-radius:10px; font-family:monospace; \n",
    "            line-height:1.4; font-size:22px; font-weight:normal; text-transform: capitalize; padding: 5px;\"\n",
    "     >Machine Learning Module: Bank Credit Scoring Dataset Classification and Regression<br><br></p>\n",
    "    \n",
    "  <div style=\"align: center;\">\n",
    "  <table style=\"text-align: center; background-color: romance; color: Jaguar; border-radius: 10px; font-family: monospace;\n",
    "                  line-height:1.4; font-size: 21px; font-weight: normal; text-transform: capitalize; padding: 5px; \n",
    "                  margin: 0 auto;\">\n",
    "    <tr><td style=\"text-align: left; padding-left: 0px;\"\n",
    "            > Virtual Enviroment with Pipenv <span style=\"font-size: 16px;\"> </span></td></tr>\n",
    "    <tr><td style=\"text-align: left; padding-left: 0px;\"\n",
    "            > Docker Deployment <span style=\"font-size: 16px;\"> </span></td></tr>\n",
    "  </table>\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a8b00d",
   "metadata": {},
   "source": [
    "**Dataset Info**\n",
    "\n",
    "> https://www.kaggle.com/datasets/kapturovalexander/bank-credit-scoring/data\n",
    "\n",
    "**About Dataset**\n",
    "\n",
    "Split dataset into train and test and clean it from null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab108c8",
   "metadata": {},
   "source": [
    "**TASK**\n",
    "\n",
    "**Homework**\n",
    "\n",
    "In this homework, we will use Bank credit scoring dataset from [here](https://www.kaggle.com/datasets/kapturovalexander/bank-credit-scoring/data).\n",
    "\n",
    "> **Note**: sometimes your answer doesn't match one of the options exactly. That's fine. \n",
    "Select the option that's closest to your solution.\n",
    "\n",
    "> **Note**: we recommend using python 3.10 in this homework.\n",
    "\n",
    "\n",
    "\n",
    "**Submit the results**\n",
    "\n",
    "- Submit your results here: https://forms.gle/gfruq6FGoLass3Ff9\n",
    "- If your answer doesn't match options exactly, select the closest one.\n",
    "- You can submit your solution multiple times. In this case, only the last submission will be used\n",
    "\n",
    "**Deadline**\n",
    "\n",
    "The deadline for submitting is October 16 (Monday), 23:00 CET. After that the form will be closed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78138c11",
   "metadata": {},
   "source": [
    "<div style=\"letter-spacing:normal; opacity:1.;\">\n",
    "  <h1 style=\"text-align:center; background-color: lightsalmon; color: Jaguar; border-radius:10px; font-family:monospace; border-radius:20px;\n",
    "            line-height:1.4; font-size:32px; font-weight:bold; text-transform: uppercase; padding: 9px;\">\n",
    "            <strong>1. Import Libraries & Ingest Data</strong></h1>   \n",
    "</div>\n",
    "\n",
    "> ⚠️ Not Recommended conda `base` env, work on `venv`\n",
    "\n",
    "- https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf\n",
    "\n",
    "**You must use the `--no-deps` option in the pip install command in order to avoid bundling dependencies into your conda-package.**\n",
    "\n",
    "If you run pip install without the `--no-deps` option, pip will often install dependencies in your conda recipe and those dependencies will become part of your package. <br>\n",
    "This wastes space in the package and `increases the risk of file overlap`, file clobbering, and broken packages.\n",
    "\n",
    "There might be cases where you want to install a package directly from a local directory or a specific location, without relying on the package indexes.<br>\n",
    "In such situations, you can use the `--no-index` option to tell pip not to look for the package in any indexes.\n",
    "\n",
    "```py\n",
    "# new conda virtual environment\n",
    "conda create --name \"classifier\" python=3.10 jupyter -y\n",
    "conda activate \"classifier\"\n",
    "\n",
    "# if The environment is inconsistent, try below\n",
    "conda update -n base -c defaults conda --force-reinstall\n",
    "conda install anaconda --force-reinstall\n",
    "\n",
    "# get dependencies\n",
    "pip freeze > requirements.txt\n",
    "conda list -e > requirements.txt\n",
    "\n",
    "# install all package dependencies\n",
    "pip install -r requirements.txt\n",
    "conda install -c conda-forge pandas==2.0.2 -q -y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12da05a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a942a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt \n",
    "# To get started with MLflow you'll need to install the appropriate Python package.\n",
    "\n",
    "# for parquet file\n",
    "pyarrow\n",
    "fastparquet\n",
    "# orjson is a fast, correct JSON library\n",
    "orjson\n",
    "numpy\n",
    "pandas\n",
    "matplotlib\n",
    "seaborn\n",
    "scipy\n",
    "tqdm\n",
    "joblib\n",
    "\n",
    "# ML Model packages\n",
    "scikit-learn\n",
    "xgboost\n",
    "optuna\n",
    "hyperopt\n",
    "\n",
    "# Optionally\n",
    "jupyter\n",
    "ipykernel\n",
    "ipywidgets\n",
    "pipenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63eff564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Windows\n",
      "Python  : 3.10.13\n",
      "Actv Env: classifier\n"
     ]
    }
   ],
   "source": [
    "import os, sys, platform, IPython.display\n",
    "\n",
    "# pip install --no-deps --no-index --force-reinstall --no-cache-dir --user\n",
    "# !{sys.executable} -m pip install -Uq -r requirements.txt --no-cache-dir --user\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "# IPython.display.clear_output()\n",
    "print(\"Platform:\", platform.system())  # platform.platform()\n",
    "print(\"Python  :\", platform.python_version())  # sys.version\n",
    "print(\"Actv Env:\", os.getenv('CONDA_DEFAULT_ENV', 'Not Found Conda Env'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662facc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jupyter ipykernel ipywidgets\n",
    "# !pip install pyarrow fastparquet orjson pandas matplotlib seaborn\n",
    "# !pip install scikit-learn xgboost optuna hyperopt\n",
    "# !pip install tqdm requests\n",
    "# !pip install pipenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe8272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Filter out FutureWarnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# warnings.filterwarnings(action=\"ignore\", message=\"FutureWarning: is_categorical_dtype*\")\n",
    "# warnings.filterwarnings(action=\"ignore\", module=\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81ffeeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "# from sklearn.linear_model import ElasticNet, Lasso, LassoCV, Ridge, RidgeCV\n",
    "# from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# import pickle\n",
    "# import click\n",
    "from glob import glob\n",
    "# Import joblib for model persistence\n",
    "# from joblib import load, dump\n",
    "\n",
    "# memory management performs garbage collection \n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712925f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "matplotlib          3.7.2\n",
      "numpy               1.25.2\n",
      "optuna              3.3.0\n",
      "pandas              2.1.0\n",
      "scipy               1.11.3\n",
      "seaborn             0.13.0\n",
      "session_info        1.0.0\n",
      "sklearn             1.3.1\n",
      "xgboost             2.0.0\n",
      "-----\n",
      "IPython             8.15.0\n",
      "jupyter_client      7.4.9\n",
      "jupyter_core        5.3.0\n",
      "jupyterlab          3.6.3\n",
      "notebook            6.5.4\n",
      "-----\n",
      "Python 3.10.13 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:24:38) [MSC v.1916 64 bit (AMD64)]\n",
      "Windows-10-10.0.22621-SP0\n",
      "-----\n",
      "Session information updated at 2023-10-17 19:23\n"
     ]
    }
   ],
   "source": [
    "# !pip install session_info\n",
    "import session_info\n",
    "session_info.show(html=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e78613e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Get the current working directory\n",
    "# current_dir = os.getcwd()\n",
    "# Create a new directory for storing data\n",
    "os.makedirs('./pycode', exist_ok=True)\n",
    "# os.makedirs('./output', exist_ok=True)\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "os.makedirs('./data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb564b98",
   "metadata": {},
   "source": [
    "<div style=\"letter-spacing:normal; opacity:1.;\">\n",
    "  <h1 style=\"text-align:center; background-color: lightsalmon; color: Jaguar; border-radius:10px; font-family:monospace; border-radius:20px;\n",
    "            line-height:1.4; font-size:32px; font-weight:bold; text-transform: uppercase; padding: 9px;\">\n",
    "            <strong>2. Recognizing and Understanding Data</strong></h1>   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada2c5e",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "In this homework, we will use Bank credit scoring dataset from [here](https://www.kaggle.com/datasets/kapturovalexander/bank-credit-scoring/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb5b120",
   "metadata": {},
   "source": [
    "### Ingest Data [wget](https://linuxways.net/centos/linux-wget-command-with-examples/) or [curl](https://daniel.haxx.se/blog/2020/09/10/store-the-curl-output-over-there/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9984fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Read the data for (May 2023)\n",
    "# Specify the ZIP file path\n",
    "zip_filename = 'data/archive.zip'\n",
    "csv_filename = 'bank.csv'\n",
    "csv_filepath = f'data/{csv_filename}'\n",
    "\n",
    "# Read the extracted CSV file\n",
    "\n",
    "# Read Specify the CSV file in the ZIP\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    # zip_ref.extract(csv_filename, path='.')\n",
    "    with zip_ref.open(csv_filename) as f_out:\n",
    "        df = pd.read_csv(f_out, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf1e3f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame: (4521, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         job  marital  education default  balance housing loan  \\\n",
       "0   30  unemployed  married    primary      no     1787      no   no   \n",
       "1   33    services  married  secondary      no     4789     yes  yes   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
       "1  cellular   11   may       220         1    339         4  failure  no  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of DataFrame:\", df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e37ed4",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Install Pipenv\n",
    "* What's the version of pipenv you installed?\n",
    "* Use `--version` to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10cef6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show pipenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6f7546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipenv, version 2023.9.1\n"
     ]
    }
   ],
   "source": [
    "!pipenv --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fa4a7",
   "metadata": {},
   "source": [
    "#### Answer 1: pipenv, version 2023.9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e9cc80",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Use Pipenv to install Scikit-Learn version 1.3.1\n",
    "* What's the first hash for scikit-learn you get in Pipfile.lock?\n",
    "\n",
    "> **Note**: you should create an empty folder for homework\n",
    "and do it there.\n",
    "\n",
    "```bash\n",
    "mkdir ml-zoomcamp-module-5-env\n",
    "cd ml-zoomcamp-module-5-env\n",
    "\n",
    "# Inside the empty folder, run the following command to initialize a new Pipenv environment:\n",
    "cd \"ml-zoomcamp-module-5-env\"\n",
    "\n",
    "# Use the desired Python version\n",
    "pipenv --python 3.10\n",
    "\n",
    "# Use the following command to install scikit-learn version 1.3.1:\n",
    "pipenv install scikit-learn==1.3.1\n",
    "\n",
    "# check version of scikit-learn installed within Pipenv environment\n",
    "pipenv run pip show scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4bb5b",
   "metadata": {},
   "source": [
    "### Pipenv environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8accc1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd \"ml-zoomcamp-module-5-env\" & pipenv run pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbdf230e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first hash for scikit-learn is: sha256:0c275a06c5190c5ce00af0acbb61c06374087949f643ef32d355ece12c4db043\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your Pipfile.lock\n",
    "pipfile_lock_path = 'ml-zoomcamp-module-5-env\\Pipfile.lock'  # Update with the correct path if necessary\n",
    "\n",
    "# Read the Pipfile.lock\n",
    "with open(pipfile_lock_path, 'r') as lock_file:\n",
    "    lock_data = json.load(lock_file)\n",
    "\n",
    "# Get the first hash for scikit-learn\n",
    "scikit_learn_hash = lock_data['default']['scikit-learn']['hashes'][0]\n",
    "\n",
    "# Print the first hash\n",
    "print(\"The first hash for scikit-learn is:\", scikit_learn_hash)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb846f50",
   "metadata": {},
   "source": [
    "#### Answer 2: The first hash for scikit-learn is: sha256:0c275a06c5190c5ce00af0acbb61c06374087949f643ef32d355ece12c4db043"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d469ecbc",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "features = ['job','duration', 'poutcome']\n",
    "dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "model = LogisticRegression().fit(X, y)\n",
    "```\n",
    "\n",
    "> **Note**: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download them:\n",
    "\n",
    "* [DictVectorizer](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/dv.bin?raw=true)\n",
    "* [LogisticRegression](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/model1.bin?raw=true)\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```bash\n",
    "PREFIX=https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework\n",
    "wget $PREFIX/model1.bin\n",
    "wget $PREFIX/dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e7addaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework\"\n",
    "!curl -Os --output-dir \"model\" $PREFIX/model1.bin\n",
    "!curl -Os --output-dir \"model\" $PREFIX/dv.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e397c5",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's use these models!\n",
    "\n",
    "* Write a script for loading these models with pickle\n",
    "* Score this client:\n",
    "\n",
    "```json\n",
    "{\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit? \n",
    "\n",
    "* 0.162\n",
    "* 0.392\n",
    "* 0.652\n",
    "* 0.902\n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```bash\n",
    "$ md5sum model1.bin dv.bin\n",
    "8ebfdf20010cfc7f545c43e3b52fc8a1  model1.bin\n",
    "924b496a89148b422c74a62dbc92a4fb  dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d6df7e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD5 hash of model/model1.bin:\n",
      "8ebfdf20010cfc7f545c43e3b52fc8a1\n",
      "CertUtil: -hashfile command completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD5 hash of model/dv.bin:\n",
      "924b496a89148b422c74a62dbc92a4fb\n",
      "CertUtil: -hashfile command completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!CertUtil -hashfile model/model1.bin MD5\n",
    "!CertUtil -hashfile model/dv.bin MD5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ad629ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that this client will get a credit is: 0.902\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the data preprocessing object\n",
    "with open('model/dv.bin', 'rb') as dv_file:\n",
    "    dv = pickle.load(dv_file)\n",
    "\n",
    "# Load the trained model\n",
    "with open('model/model1.bin', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "# Define the client data as a dictionary\n",
    "client_data = {\n",
    "    \"job\": \"retired\",\n",
    "    \"duration\": 445,\n",
    "    \"poutcome\": \"success\"\n",
    "}\n",
    "\n",
    "# Use the data preprocessing object to transform the client data\n",
    "X = dv.transform([client_data])  # Pass the client_data as a list containing a single dictionary\n",
    "\n",
    "# Make a probability prediction using the loaded model\n",
    "probability = model.predict_proba(X)[:, 1]\n",
    "\n",
    "print(f\"The probability that this client will get a credit is: {probability[0]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d52d78",
   "metadata": {},
   "source": [
    "What's the probability that this client will get a credit? \n",
    "\n",
    "* 0.162\n",
    "* 0.392\n",
    "* 0.652\n",
    "* **0.902**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb37b0d",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install Flask and gunicorn (or waitress, if you're on Windows)\n",
    "* Write Flask code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit?\n",
    "\n",
    "* 0.140\n",
    "* 0.440\n",
    "* 0.645\n",
    "* 0.845\n",
    "\n",
    "\n",
    "```bash\n",
    "# Install Flask and gunicorn (or waitress for Windows):\n",
    "pipenv install flask\n",
    "pipenv install gunicorn\n",
    "pipenv install waitress\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5bf1ec",
   "metadata": {},
   "source": [
    "### Write Flask Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "31717475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pycode/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pycode/app.py\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the data preprocessing object and the trained model\n",
    "with open('../model/dv.bin', 'rb') as dv_file, open('../model/model1.bin', 'rb') as model_file:\n",
    "    dv = pickle.load(dv_file)\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "\n",
    "    # Use the data preprocessing object to transform the input data\n",
    "    X = dv.transform([data])\n",
    "\n",
    "    # Make a probability prediction using the loaded model\n",
    "    probability = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return jsonify({'probability': probability[0]})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55d569e",
   "metadata": {},
   "source": [
    "### Run the Flask App using Pipenv\n",
    "\n",
    "```py\n",
    "# activate pipenv via Using Pipfile, cd env_path\n",
    "pip shell\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4bc07906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd app.py_path\n",
    "\n",
    "# Run the Flask app using Pipenv, which ensures it runs within the virtual environment\n",
    "# gunicorn -w 4 -b 0.0.0.0:8000 app:app  # For Linux/macOS\n",
    "\n",
    "# if you're on Windows and using Waitress\n",
    "# waitress-serve --port=8000 app:app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5166f7b",
   "metadata": {},
   "source": [
    "### Score the client using requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5d8fe35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pycode/score_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pycode/score_client.py\n",
    "\n",
    "import requests\n",
    "\n",
    "# To access your Flask application served by Waitress, \n",
    "# you should use http://localhost:8000 or http://127.0.0.1:8000 in your web browser. \n",
    "url = \"http://127.0.0.1:8000\"  # Replace with your actual URL\n",
    "\n",
    "client = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "\n",
    "response = requests.post(url, json=client).json()\n",
    "print(f\"The probability that this client will get a credit is: {response['probability']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4e780845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that this client will get a credit is: 0.140\n"
     ]
    }
   ],
   "source": [
    "!python pycode/score_client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de46225",
   "metadata": {},
   "source": [
    "What's the probability that this client will get a credit?\n",
    "\n",
    "* **0.140**\n",
    "* 0.440\n",
    "* 0.645\n",
    "* 0.845"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca703c1",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "Install [Docker](https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/05-deployment/06-docker.md).<br>\n",
    "We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `svizor/zoomcamp-model:3.10.12-slim`.<br>\n",
    "You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "```sh \n",
    "# Pull the Docker image:\n",
    "docker pull svizor/zoomcamp-model:3.10.12-slim\n",
    "\n",
    "# Check the size of the downloaded image:\n",
    "docker images\n",
    "```\n",
    "\n",
    "This image is based on `python:3.10.12-slim` and has a logistic regression model<br>\n",
    "(a different one) as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```docker \n",
    "FROM python:3.10.12-slim\n",
    "WORKDIR /app\n",
    "COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "\n",
    "We already built it and then pushed it to [`svizor/zoomcamp-model:3.10.12-slim`](https://hub.docker.com/r/svizor/zoomcamp-model).\n",
    "\n",
    "> **Note**: You don't need to build this docker image, it's just for your reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "57545db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12-slim: Pulling from svizor/zoomcamp-model\n",
      "Digest: sha256:e8441100b9d8da56344f50c673eb2daded3c61ce9565e45c3592c02f34fb3149\n",
      "Status: Image is up to date for svizor/zoomcamp-model:3.10.12-slim\n",
      "docker.io/svizor/zoomcamp-model:3.10.12-slim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "What's Next?\n",
      "  View a summary of image vulnerabilities and recommendations → docker scout quickview svizor/zoomcamp-model:3.10.12-slim\n"
     ]
    }
   ],
   "source": [
    "!docker pull svizor/zoomcamp-model:3.10.12-slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b89441de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY              TAG            IMAGE ID       CREATED      SIZE\n",
      "svizor/zoomcamp-model   3.10.12-slim   08266c8f0c4b   8 days ago   147MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc203f57",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit now?\n",
    "\n",
    "* 0.168\n",
    "* 0.530\n",
    "* 0.730\n",
    "* 0.968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c2241799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pycode/app2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pycode/app2.py\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the data preprocessing object and the trained model\n",
    "with open('dv.bin', 'rb') as dv_file, open('model2.bin', 'rb') as model_file:\n",
    "    dv = pickle.load(dv_file)\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "\n",
    "    # Use the data preprocessing object to transform the input data\n",
    "    X = dv.transform([data])\n",
    "\n",
    "    # Make a probability prediction using the loaded model\n",
    "    probability = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return jsonify({'probability': probability[0]})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "486c31e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# Use the ml-zoomcamp image\n",
    "FROM svizor/zoomcamp-model:3.10.12-slim\n",
    "\n",
    "# Set the working directory in the container\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy the application code into the container\n",
    "COPY pycode/ /app/\n",
    "\n",
    "# Copy the Pipfile and Pipfile.lock into the container\n",
    "COPY ml-zoomcamp-module-5-env/ /app/\n",
    "\n",
    "# Install pipenv and the project dependencies\n",
    "RUN pip install pipenv && \\\n",
    "    pipenv install --deploy --ignore-pipfile\n",
    "\n",
    "# Expose the port that Flask will run on\n",
    "EXPOSE 8000\n",
    "\n",
    "# Start the Flask application using pipenv\n",
    "CMD [\"pipenv\", \"run\", \"waitress-serve --port=8000 app2:app\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "97a898fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load .dockerignore\n",
      "#1 transferring context:\n",
      "#1 transferring context: 2B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load build definition from Dockerfile\n",
      "#2 transferring dockerfile: 610B 0.0s done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/svizor/zoomcamp-model:3.10.12-slim\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [1/5] FROM docker.io/svizor/zoomcamp-model:3.10.12-slim\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [2/5] WORKDIR /app\n",
      "#5 CACHED\n",
      "\n",
      "#6 [internal] load build context\n",
      "#6 transferring context: 1.05kB done\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [3/5] COPY pycode/ /app/\n",
      "#7 DONE 0.0s\n",
      "\n",
      "#8 [4/5] COPY ml-zoomcamp-module-5-env/ /app/\n",
      "#8 DONE 0.0s\n",
      "\n",
      "#9 [5/5] RUN pip install pipenv &&     pipenv install --deploy --ignore-pipfile\n",
      "#9 3.769 Collecting pipenv\n",
      "#9 3.992   Downloading pipenv-2023.10.3-py3-none-any.whl (3.2 MB)\n",
      "#9 4.488      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 6.5 MB/s eta 0:00:00\n",
      "#9 4.824 Collecting virtualenv>=20.24.2\n",
      "#9 4.848   Downloading virtualenv-20.24.5-py3-none-any.whl (3.7 MB)\n",
      "#9 5.323      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.7/3.7 MB 8.0 MB/s eta 0:00:00\n",
      "#9 5.921 Collecting setuptools>=67\n",
      "#9 5.945   Downloading setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
      "#9 6.067      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 807.9/807.9 kB 6.8 MB/s eta 0:00:00\n",
      "#9 6.158 Collecting certifi\n",
      "#9 6.182   Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "#9 6.215      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.3/158.3 kB 5.6 MB/s eta 0:00:00\n",
      "#9 6.314 Collecting distlib<1,>=0.3.7\n",
      "#9 6.343   Downloading distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n",
      "#9 6.433      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.9/468.9 kB 5.4 MB/s eta 0:00:00\n",
      "#9 6.524 Collecting platformdirs<4,>=3.9.1\n",
      "#9 6.547   Downloading platformdirs-3.11.0-py3-none-any.whl (17 kB)\n",
      "#9 6.650 Collecting filelock<4,>=3.12.2\n",
      "#9 6.680   Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "#9 7.159 Installing collected packages: distlib, setuptools, platformdirs, filelock, certifi, virtualenv, pipenv\n",
      "#9 7.308   Attempting uninstall: setuptools\n",
      "#9 7.309     Found existing installation: setuptools 65.5.1\n",
      "#9 7.398     Uninstalling setuptools-65.5.1:\n",
      "#9 7.498       Successfully uninstalled setuptools-65.5.1\n",
      "#9 11.68 Successfully installed certifi-2023.7.22 distlib-0.3.7 filelock-3.12.4 pipenv-2023.10.3 platformdirs-3.11.0 setuptools-68.2.2 virtualenv-20.24.5\n",
      "#9 11.68 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#9 12.00 \n",
      "#9 12.00 [notice] A new release of pip is available: 23.0.1 -> 23.3\n",
      "#9 12.00 [notice] To update, run: pip install --upgrade pip\n",
      "#9 13.22 Creating a virtualenv for this project...\n",
      "#9 13.22 Pipfile: /app/Pipfile\n",
      "#9 13.24 Using /usr/local/bin/python3 (3.10.12) to create virtualenv...\n",
      "#9 14.92 created virtual environment CPython3.10.12.final.0-64 in 1299ms\n",
      "#9 14.92   creator CPython3Posix(dest=/root/.local/share/virtualenvs/app-4PlAip0Q, clear=False, no_vcs_ignore=False, global=False)\n",
      "#9 14.92   seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
      "#9 14.92     added seed packages: pip==23.2.1, setuptools==68.2.0, wheel==0.41.2\n",
      "#9 14.92   activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
      "#9 14.92 \n",
      "#9 14.92 ✔ Successfully created virtual environment!\n",
      "#9 14.99 Virtualenv location: /root/.local/share/virtualenvs/app-4PlAip0Q\n",
      "#9 15.03 Installing dependencies from Pipfile.lock (f949be)...\n",
      "#9 DONE 45.1s\n",
      "\n",
      "#10 exporting to image\n",
      "#10 exporting layers\n",
      "#10 exporting layers 4.3s done\n",
      "#10 writing image sha256:93b916ae25bb555a9bd12dbb95bca22854393c6fc04f54f030024c149da022f2 done\n",
      "#10 naming to docker.io/library/my-flask-app done\n",
      "#10 DONE 4.4s\n",
      "\n",
      "What's Next?\n",
      "  View a summary of image vulnerabilities and recommendations → docker scout quickview\n"
     ]
    }
   ],
   "source": [
    "!docker build -t my-flask-app ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f38c0b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87c87fbb35a24eca7cd2a85fdb0ce1422a8d97bec8c6766b0a9c1de8cc4a0fb5\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm -d -p 8000:8000 my-flask-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "82109816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS         PORTS                    NAMES\n",
      "87c87fbb35a2   my-flask-app   \"pipenv run python a…\"   9 minutes ago   Up 9 minutes   0.0.0.0:8000->8000/tcp   youthful_pascal\n"
     ]
    }
   ],
   "source": [
    "# List running containers and their ports\n",
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8c2b3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo netstat -tuln | grep 8000\n",
    "# !netstat -ano | findstr \"8000\"\n",
    "# !taskkill /F /PID xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1bdeee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pycode/score_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pycode/score_client.py\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000\"  # Replace with your actual URL\n",
    "client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "response = requests.post(url, json=client).json()\n",
    "print(f\"The probability that this client will get a credit is: {response['probability']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d2865280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that this client will get a credit is: 0.727\n"
     ]
    }
   ],
   "source": [
    "!python pycode/score_client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7c4fd",
   "metadata": {},
   "source": [
    "## End of Project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
